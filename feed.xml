<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.4">Jekyll</generator><link href="https://ltinphan.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://ltinphan.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2025-06-21T06:06:23+00:00</updated><id>https://ltinphan.github.io/feed.xml</id><title type="html">Tin Robotics</title><subtitle>A Robotics PhD crafting legged robots, autopilots for autonomous vehicles, and fleet management systems for coordinating mobile robots in warehouses and factories. This is my space to share research, projects, and ideas. </subtitle><entry><title type="html">Run Huggingface Models Locally For Free</title><link href="https://ltinphan.github.io/blog/2025/huggingface-local/" rel="alternate" type="text/html" title="Run Huggingface Models Locally For Free"/><published>2025-06-15T15:09:00+00:00</published><updated>2025-06-15T15:09:00+00:00</updated><id>https://ltinphan.github.io/blog/2025/huggingface-local</id><content type="html" xml:base="https://ltinphan.github.io/blog/2025/huggingface-local/"><![CDATA[<p>If you’ve been following AI advancements in the open-source space, you’ve likely heard of Hugging Face. This French-American company is dedicated to open-source machine learning tools, particularly focusing on natural language processing. Hugging Face is named after a cute emoji.</p> <h2 id="hugging-faces-core-offerings">Hugging Face’s Core Offerings</h2> <p>Hugging Face provides several key tools to empower developers and researchers in the AI community:</p> <ul> <li><strong>Transformers Library</strong>: This is a collection of pre-trained models designed for various tasks such as text classification, translation, summarization, and more.</li> <li><strong>Datasets Library</strong>: A repository offering ready-to-use datasets for training and evaluating machine learning models.</li> <li><strong>Hugging Face Hub</strong>: A central platform that functions like the GitHub of AI, allowing users to share and explore models, datasets, and machine learning applications. It facilitates collaboration among machine learning enthusiasts and experts, enabling them to learn from each other’s work and experience.</li> </ul> <h2 id="understanding-key-hugging-face-terminologies">Understanding Key Hugging Face Terminologies</h2> <p>To maximize your experience with Hugging Face, it’s helpful to understand some core terms:</p> <h3 id="pre-trained-model">Pre-trained Model</h3> <p>A pre-trained model is a machine learning model that has already been taught using a large amount of data for a specific task, such as recognizing images or understanding language. This means you can use it immediately without needing to train it from scratch.</p> <h3 id="inference">Inference</h3> <p>Inference is the process where a trained model makes predictions or draws conclusions about new, previously unseen data, based on patterns it learned during its training phase.</p> <h3 id="training">Training</h3> <p>Training is the initial phase of the machine learning process where the machine learns by being exposed to numerous examples. For instance, if you’re teaching it to recognize cars, you provide it with many labeled pictures of different cars, allowing the machine to build its understanding. Once trained, the machine uses this acquired knowledge during inference to recognize new things, like a car it hasn’t seen before.</p> <h3 id="transformers">Transformers</h3> <p>Transformers are a type of model specifically designed to handle text-based tasks, including translation, summarization, and text generation. Their unique architecture uses “attention mechanisms” to identify and capture the relationships between words and sentences.</p> <h3 id="tokenizer">Tokenizer</h3> <p>A tokenizer is a process that breaks down text into smaller units known as tokens. These tokens are typically words or subwords and are essential for natural language processing tasks.</p> <h2 id="getting-started-with-hugging-face">Getting Started with Hugging Face</h2> <p>To begin using Hugging Face, you’ll need to set up an account and install the necessary libraries and dependencies.</p> <h3 id="account-setup">Account Setup</h3> <p>Signing up as a community individual contributor is free. You can create a free account by visiting the Hugging Face website and clicking “sign up”. You may need to complete a quick human verification, then enter your email and password, complete your profile, and generate an avatar. After creating the account, you’ll receive a verification link in your email that you must click to verify your address. Once verified, you are officially a Hugging Face member. For more features or organizational needs, pro or customized plans are available.</p> <h3 id="environment-setup-python-pip-and-virtual-environments">Environment Setup: Python, Pip, and Virtual Environments</h3> <p>Before using the Hugging Face Hub programmatically, you must set up your environment:</p> <ol> <li><strong>Install Python and Pip</strong>: Ensure Python 3.8 or higher is installed. Pip, Python’s package manager, is included with Python and doesn’t need separate installation.</li> <li><strong>Create a Virtual Environment</strong>: It’s recommended to create a virtual environment to isolate project dependencies from system-wide packages, leading to a cleaner and more manageable setup. Common options include <code class="language-plaintext highlighter-rouge">Venv</code> (included with Python 3.3+) and <code class="language-plaintext highlighter-rouge">Conda</code> (installed via Anaconda or Miniconda), which is popular for data science and ML projects. You can activate your environment using the <code class="language-plaintext highlighter-rouge">conda activate</code> command.</li> <li><strong>Choose a Code Editor/IDE</strong>: For development, you can use any preferred code editor or IDE, such as Jupyter Notebook, PyCharm, or Visual Studio Code.</li> </ol> <h3 id="installing-hugging-face-libraries">Installing Hugging Face Libraries</h3> <p>Hugging Face offers two main libraries for accessing pre-trained models:</p> <ul> <li><strong>Transformers</strong>: This library handles text-based tasks like translation, summarization, and text generation. Install it using <code class="language-plaintext highlighter-rouge">pip install transformers</code>.</li> <li><strong>Diffusers</strong>: This library manages image-based tasks, including image synthesis, image editing, and image captioning.</li> </ul> <p>To enable the <code class="language-plaintext highlighter-rouge">pipeline</code> function (discussed next) to load models, you’ll also need a model backend like PyTorch or TensorFlow. To install TensorFlow, run <code class="language-plaintext highlighter-rouge">pip install TensorFlow</code>.</p> <h2 id="using-pre-trained-models-with-hugging-face">Using Pre-trained Models with Hugging Face</h2> <h3 id="the-pipeline-function">The Pipeline Function</h3> <p>The <code class="language-plaintext highlighter-rouge">pipeline</code> function, imported from the Hugging Face Transformers library, is a high-level helper function that simplifies the use of pre-trained models for common tasks. It automates processes like loading the appropriate model, tokenizing input, running the model, and formatting output, requiring only a few lines of code.</p> <h3 id="example-sentiment-analysis-with-distilbert">Example: Sentiment Analysis with DistilBERT</h3> <p>Here’s how you can use the <code class="language-plaintext highlighter-rouge">pipeline</code> function for sentiment analysis:</p> <ol> <li><strong>Import the pipeline</strong>: <code class="language-plaintext highlighter-rouge">from transformers import pipeline</code>.</li> <li><strong>Load the pre-trained model</strong>: Use <code class="language-plaintext highlighter-rouge">pipeline</code> with the <code class="language-plaintext highlighter-rouge">sentiment-analysis</code> parameter and specify a model like <code class="language-plaintext highlighter-rouge">"distilbert-base-uncased-finetuned-sst2-english"</code>. <ul> <li><code class="language-plaintext highlighter-rouge">DistilBERT</code> is a smaller, faster version of the BERT model.</li> <li><code class="language-plaintext highlighter-rouge">base uncased</code> means it processes lowercase text and disregards capitalization.</li> <li><code class="language-plaintext highlighter-rouge">fine-tuned on SST2</code> indicates it was specifically trained for sentiment classification using the SST2 dataset.</li> </ul> <p>This setup creates a ready-to-use tool to determine if a sentence’s sentiment is positive or negative.</p> </li> <li><strong>Analyze text</strong>: Store your desired text in a variable (e.g., <code class="language-plaintext highlighter-rouge">inputtext</code>), then call the <code class="language-plaintext highlighter-rouge">pipeline</code> with this variable and print the output.</li> <li><strong>Run the code</strong>: Ensure the correct Conda environment is active. If using VS Code, select the appropriate Python interpreter via the command palette (Shift+Command+P). Execute the Python file from the terminal (e.g., <code class="language-plaintext highlighter-rouge">python your_file_name.py</code>).</li> </ol> <p>The model will return the sentiment analysis. For example, it identified one text as negative with 99.96% confidence and another positive sentence confidently as positive. The process demonstrates how straightforward it is to get a pre-trained model running using Hugging Face libraries. A dependency conflict (Keras) was resolved by installing the recommended version during one execution.</p> <h2 id="discovering-and-exploring-models">Discovering and Exploring Models</h2> <p>Finding the right pre-trained model for a specific task is simple on the Hugging Face website. You can browse models and filter them by task, library, language, and other criteria. Models and datasets can also be searched by keyword and sorted by trending, most likes, most downloads, or recent updates.</p> <p>Every model on the Hugging Face Hub has a “model card” containing important information such as model details, usage examples, links to files, and community interaction features. You can also view “Spaces” that use a particular model and explore them further or even clone a Space to your local machine to run it yourself.</p>]]></content><author><name></name></author><category term="external-services"/><category term="AI"/><category term="code"/><summary type="html"><![CDATA[a step-to-step guideline to run huggingface models locally]]></summary></entry></feed>